%Jennifer Pan, August 2011

\documentclass[10pt,letter]{article}
	% basic article document class
	% use percent signs to make comments to yourself -- they will not show up.

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bbm}
\usepackage{enumitem}
	% packages that allow mathematical formatting

\usepackage{graphicx}
	% package that allows you to include graphics

\usepackage{setspace}
	% package that allows you to change spacing

\onehalfspacing
	% text become 1.5 spaced

\usepackage{fullpage}
	% package that specifies normal margins


\begin{document}
	% line of code telling latex that your document is beginning


\title{ECON550: Problem Set 3}

\author{Nicholas Wu}

\date{Fall 2020}
	% Note: when you omit this command, the current dateis automatically included

\maketitle
	% tells latex to follow your header (e.g., title, author) commands.
\section*{HMC Exercises (7th edition)}
\paragraph{1.8.2}
We have
\[ \mathbb{E}[X] = \int_{-2}^4 \frac{x(x+2)}{18} \ dx = 2 \]
\[ \mathbb{E}[(X+2)^3] = \int_{-2}^4 \frac{(x+2)^4}{18} \ dx = \frac{432}{5} \]
\paragraph{1.8.3}
\[ \mathbb{E}[X] = 3 \]
\[ \mathbb{E}[X^2] = 11 \]
\[ \mathbb{E}[(X+2)^2] = \mathbb{E}[X^2] + 4\mathbb{E}[X] + 4 = 11 + 12 + 4 = 27 \]
\paragraph{1.8.6}
\[ \mathbb{E}[X(1-X)] = \mathbb{E}[X] - \mathbb{E}[X^2] = \frac{3}{4} - \frac{3}{5} = \frac{3}{20} \]
\paragraph{1.8.10}
$X$ is symmetrically distributed about $0$ because the distribution function only uses $x^2$, which is symmetric about 0. However, $E(X) \neq 0$ because the integral
\[ \int \frac{1}{\pi} \frac{x}{x^2 + 1} \]
doesn't converge.
\paragraph{1.9.3a}
From a symmetry observation,
\[ \mu = \frac{1}{2} \]
The variance is
\[ \sigma^2 = \int _0^1 (x-0.5)^2 6x(1-x) \ dx = 0.05 \]
\[ \sigma = \frac{\sqrt{5}}{10} \]
So the desired probability is
\[ \int_{\frac{1}{2} - \frac{\sqrt{5}}{5}}^{\frac{1}{2} + \frac{\sqrt{5}}{5}} 6x(1-x) \ dx = \frac{11}{5\sqrt{5}} \approx 0.98 \]
\paragraph{1.9.6}
We use linearity of expectation:
\[ E[(X-\mu)/\sigma] = \frac{E(X) - \mu }{\sigma} = 0 \]
since $\mu = E[X]$. Also,
\[ E\left[\left(\frac{X-\mu}{\sigma}\right)^2\right] = \frac{E[X^2 - 2X\mu + \mu^2]}{\sigma^2} = \frac{E[X^2] - E[X]^2}{\sigma^2} = 1 \]
Finally,
\[ E\left[\exp\left(t\frac{X-\mu}{\sigma} \right)\right] = e^{-t\mu/\sigma}E\left[\exp\left(t\frac{X}{\sigma} \right)\right]  = e^{-t\mu/\sigma} M\left(\frac{t}{\sigma} \right)\]
\paragraph{1.9.20}
\[E[X] = \int_0^b x f(x) \ dx = xF(x) |_0^b - \int_0^b F(x) dx = b - \int_0^b F(x) = \int_0^b (1 - F(x)) \ dx \]
\paragraph{1.9.24}
The expected value is
\[ \mu = \int x \sum_i c_i f_i = \int \sum_i c_i (x f_i) = \sum_i \int c_i (x f_i) = \sum_i c_i \int xf_i = \sum_i c_i \mu_i \]
The variance is
\[ \sigma^2 = \int (x - \mu)^2 \sum_i c_i f_i = \sum_i c_i \int (x - \mu)^2 f_i = \sum_i c_i \int (x^2 - 2\mu x + \mu^2 - 2\mu_i + 2\mu_i + \mu_i^2 - \mu_i^2) f_i   \]

\[ = \sum_i c_i \int (x^2 - 2\mu_i + \mu_i^2 + 2\mu_i - 2\mu x + \mu^2  - \mu_i^2) f_i \]
\[ = \sum_i c_i \int (x^2 - 2\mu_i x + \mu_i^2)f_i + ( 2\mu_i x - 2\mu x + \mu^2  - \mu_i^2) f_i  \]
\[ = \sum_i c_i \int (x - \mu_i)^2 f_i + ( 2\mu_i  - 2\mu) x f_i + (\mu^2  - \mu_i^2) f_i  \]

\[ = \sum_i c_i \left( \sigma_i^2 + ( 2\mu_i  - 2\mu)\mu_i + (\mu^2  - \mu_i^2) \right) \]
\[ = \sum_i c_i \left( \sigma_i^2 + 2\mu_i^2  - 2\mu\mu_i + \mu^2  - \mu_i^2 \right) \]
\[ = \sum_i c_i \left( \sigma_i^2 + \mu_i^2  - 2\mu\mu_i + \mu^2   \right) \]
\[ = \sum_i c_i \left( \sigma_i^2 + (\mu_i - \mu)^2   \right) \]
\paragraph{1.10.3}
The variance is
\[ \sigma^2 = E[X^2] - E[X]^2 = 4 \]
\[ \sigma = 2 \]
So
\[ P(-2 < X < 8) = 1 - P(|X - 3| \ge 5) = 1 - P(|X-\mu| \ge \frac{5}{2}\sigma) \ge 1 - \frac{4}{25} = \frac{21}{25} \]
\paragraph{1.10.4}
By Markov's inequality,
\[ P(X \ge a) = P(e^{tX} \ge e^{ta}) \le \frac{E[e^{tX}]}{e^ta} = e^{-at} M(t) \]
Also, by Markov's inequality,
\[ P(X \le a) = P(e^{-tX} \le e^{-ta}) = P(e^{tX} \ge e^{ta}) \le \frac{E[e^{tX}]}{e^{at}} = e^{-at} M(t) \]
\paragraph{1.10.6a}
The function $\phi(x) = 1/x$ is convex (second derivative is $2/x^3$, positive for positive $x$), so by Jensen's inequality,
\[ E[1/X] = E[\phi(X)] \ge \phi(E[X]) = 1/E[X] \]
\paragraph{1.10.6b}
The function $\phi(x) = -\log x$ is convex, since it has second derivative $1/x^2$, which is positive for positive $x$. So by Jensen's,
\[ E[-\log X] = E[\phi(X) ] \ge \phi(E[X]) = -\log E[X] \]
\paragraph{3.1.3}
Using linearity and the fact that a binomial RV has expectation $np$ and variance $np(1-p)$, we get
\[ E\left[\frac{X}{n}\right] = \frac{np}{n} = p\]
\[E\left[\left( \frac{X}{n} - p\right)^2\right] = E\left[\frac{(X - pn)^2}{n^2} \right] = \frac{np(1-p)}{n^2} = \frac{p(1-p)}{n}  \]
\paragraph{3.1.6}
The probability of no successes is given by
\[\left(\frac{3}{4}\right)^n \]
We need
\[(3/4)^n \le 0.3 \]
\[ n \ge \log_{3/4} 0.3 \approx 4.185 \]
Hence, we need $n \ge 5$ to ensure that the probability of at least one success is at least 0.7.
\paragraph{3.1.14}
The probability $X < 3$ is given by
\[ (1/3) + (2/9) + (4/27) = \frac{19}{27} \]
So the probability $X \ge 3$ is
\[ \frac{8}{27} \]
So the conditional PMF is given by
\[ p(x | x \ge 3) = \frac{9}{8} \left(\frac{2}{3} \right)^x = \frac{1}{3} \left(\frac{2}{3} \right)^{x-3} \]
\paragraph{3.1.23}
The desired probabilities are
\[ P(X \ge k + j | X \ge k) = \frac{P(X \ge k+j)}{P(X \ge k)} \]
\[ = \frac{(1-p)^{k+j}}{(1-p)^k} = (1-p)^j = P(X \ge j) \]
\section*{Problem 2}
We will assume $g$ is measureable, as in the question prompt.
We note that $\nu$ satisfies countable disjoint additivity due to additivity of the Lebesgue integral:
\[ \nu(\cup A_i) = \int \sum_i 1_{A_i} g \ d\mu = \sum_i \int_{A_i} g d\mu = \sum_i \nu(A_i)\]
(in the second step, we skip the result that the textbook showed using monotone convergence).
Hence, we just need nonnegativity. That is, we will require
\[ \int_A g \ d\mu \ge 0  \]
So $g$ is nonnegative.

\section*{Problem 3}
\begin{enumerate}[label=(\alph*)]
\item Suppose $\rho(A) = 0$. Then since $\mu << \rho$, $\mu(A) = 0$. Since $\nu << \mu$, $\nu(A) = 0$. Hence $\nu << \rho$.
\item By Radon-Nikodym, let
\[ \nu(A) = \int_A f d\rho  \]
\[ \nu(A) = \int_A g d\mu  \]
\[ \mu(A) = \int_A h d\rho  \]
Note we have
\[ \nu(A) = \int 1_A g d\mu = \int 1_A g h d\rho = \int_A gh d\rho \]
But since this holds for all $A$, we must have
\[ f = gh \]
\[ \frac{d\nu}{d\rho} = (d\nu/d\mu)(d\mu/d\rho) \]
\end{enumerate}
\section*{Problem 4}
\begin{enumerate}[label=(\alph*)]
\item Clearly, for any $A$,
\[ \mu(A) = \int_A d\mu = \int_A \frac{d\mu}{d\mu} d\mu \]
Hence $d\mu/d\mu = 1$.
\item
We have:
\[ \mu(A) = \int_A d\mu = \int_A (d\mu/d\nu) d\nu = \int_A (d\mu/d\nu)(d\nu/d\mu) d\mu \]
Hence
\[ (d\mu/d\nu)(d\nu/d\mu) = d\mu/d\mu = 1 \]
So we get the desired result.
\end{enumerate}
\end{document}
	% line of code telling latex that your document is ending. If you leave this out, you'll get an error
